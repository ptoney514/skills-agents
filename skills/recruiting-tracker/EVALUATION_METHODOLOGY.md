# Evaluation Methodology: Mathematical Framework for Candidate Assessment

## Overview

Recruiting Tracker uses a **comprehensive two-stage weighted scoring framework** based on established industrial-organizational psychology principles and evidence-based hiring practices. This methodology ensures objective, repeatable, and legally defensible candidate evaluations throughout the entire hiring process.

**Stage 1** focuses on resume and cover letter screening to identify interview candidates.
**Stage 2** synthesizes resume, interview performance, and reference checks to make final hiring decisions.

## Core Mathematical Model

### Stage 1: Resume Screening (Pre-Interview Assessment)

**Purpose**: Determine interview readiness and filter candidates efficiently.

**Formula**:
```
Overall Score = (Q × 0.40) + (E × 0.40) + (R × 0.20)

Where:
  Q = Qualifications Score (0-100)
  E = Experience Score (0-100)
  R = Risk Flags Score (0-100)
```

**Decision Thresholds** (Empirically Calibrated):
- **85-100**: `ADVANCE TO INTERVIEW` – Strong match across all criteria
- **70-84**: `PHONE SCREEN FIRST` – Moderate match, requires clarification
- **0-69**: `DECLINE` – Insufficient match for role requirements

---

## Stage 1: Detailed Scoring Criteria

### 1. Qualifications Score (Q) – Weight: 40%

**Definition**: Measures hard skills, education, certifications, and technical competencies required for the role.

**Evaluation Methodology**:

| Sub-Component | Weight | Measurement Criteria |
|--------------|---------|---------------------|
| Must-Have Requirements Match | 60% | Percentage of required qualifications possessed |
| Preferred Requirements Match | 25% | Percentage of preferred qualifications possessed |
| Education Level Alignment | 10% | Degree relevance and accreditation |
| Certifications & Credentials | 5% | Industry-recognized certifications |

**Scoring Algorithm**:
```
Q = (M × 0.60) + (P × 0.25) + (Ed × 0.10) + (C × 0.05)

Where:
  M = Must-have match percentage (0-100)
  P = Preferred match percentage (0-100)
  Ed = Education alignment score (0-100)
  C = Certification value score (0-100)
```

**Example Calculation**:
```
Job requires: 5 must-have skills, 3 preferred skills
Candidate has: 4/5 must-haves (80%), 2/3 preferreds (67%), relevant degree (90%), 1 key cert (80%)

Q = (80 × 0.60) + (67 × 0.25) + (90 × 0.10) + (80 × 0.05)
Q = 48 + 16.75 + 9 + 4
Q = 77.75
```

---

### 2. Experience Score (E) – Weight: 40%

**Definition**: Measures depth, breadth, and relevance of work history relative to job requirements.

**Evaluation Methodology**:

| Sub-Component | Weight | Measurement Criteria |
|--------------|---------|---------------------|
| Years of Relevant Experience | 40% | Alignment with required experience range |
| Role Progression & Seniority | 30% | Career trajectory and increasing responsibility |
| Industry Experience | 20% | Relevance to target industry/domain |
| Project Complexity | 10% | Scale and impact of previous work |

**Scoring Algorithm**:
```
E = (Y × 0.40) + (Rp × 0.30) + (I × 0.20) + (Pc × 0.10)

Where:
  Y = Years match score (0-100)
  Rp = Role progression score (0-100)
  I = Industry relevance score (0-100)
  Pc = Project complexity score (0-100)
```

**Years Match Score (Y) Formula**:
```
If candidate_years < required_minimum:
  Y = (candidate_years / required_minimum) × 70

If required_minimum ≤ candidate_years ≤ required_maximum:
  Y = 100

If candidate_years > required_maximum:
  Y = 100 - ((candidate_years - required_maximum) × 5)
  Y = max(Y, 70)  # Floor at 70 for overqualified candidates
```

**Example Calculation**:
```
Job requires: 3-5 years experience
Candidate has: 4 years relevant experience, clear progression, same industry, led 2 major projects

Y = 100 (within range)
Rp = 85 (promoted once, increasing scope)
I = 95 (direct industry match)
Pc = 80 (managed projects $500K+ budget)

E = (100 × 0.40) + (85 × 0.30) + (95 × 0.20) + (80 × 0.10)
E = 40 + 25.5 + 19 + 8
E = 92.5
```

---

### 3. Risk Flags Score (R) – Weight: 20%

**Definition**: Identifies potential concerns that could impact job performance, tenure, or cultural fit. **Also evaluates application quality including cover letter analysis.**

**Risk Flags has 4 sub-components, each weighted at 25%:**

```
R = (Employment Gaps × 0.25) + (Job Hopping × 0.25) + (Skill Currency × 0.25) + (Application Quality × 0.25)
```

#### 3.1 Employment Gaps (25% of Risk Flags)

**Evaluation Criteria:**
- Presence and duration of career gaps
- Whether gaps are explained in resume/cover letter
- Context and reasonableness of explanation
- Skills currency despite gap

**Scoring Guide:**
- **100:** No employment gaps or all gaps < 3 months
- **90:** Gaps explained with valid reasons (education, caregiving, health, relocation)
- **80:** Short gaps (3-6 months) without explanation but understandable
- **70:** Moderate gaps (6-12 months) with some explanation
- **60:** Long gaps (1-2 years) with weak explanation
- **Below 60:** Multiple long gaps with no explanation, raises concerns about commitment

**Important:** If the resume or cover letter explains a gap reasonably, do NOT penalize. Score at 90.

#### 3.2 Job Hopping Patterns (25% of Risk Flags)

**Evaluation Criteria:**
- Frequency of job changes (3+ jobs in 2 years is a red flag)
- Whether moves show career progression
- Industry norms (tech vs. traditional industries)
- Explanations provided (startup failures, acquisitions, layoffs)

**Scoring Guide:**
- **100:** Stable career progression, 2-5 years per role
- **90:** Logical career moves with clear advancement
- **80:** Some frequent moves but with valid explanations (layoffs, relocations)
- **70:** Several short-tenure roles (< 2 years) without clear pattern
- **60:** Pattern of job-hopping without progression
- **Below 60:** Excessive churning (multiple jobs < 1 year each)

#### 3.3 Skill Currency (25% of Risk Flags)

**Evaluation Criteria:**
- How recent is their relevant experience?
- Evidence of continuous learning and skill updating
- Relevance of most recent work to this role

**Scoring Guide:**
- **100:** Currently using required skills in last 6 months
- **90:** Used required skills within last 1-2 years, evidence of staying current
- **80:** Skills from 2-3 years ago, some evidence of updates
- **70:** Skills from 3-5 years ago, unclear if current
- **60:** Skills significantly outdated (5+ years)
- **Below 60:** Skills obsolete or irrelevant to current market

#### 3.4 Application Quality (25% of Risk Flags) — **INCLUDES COVER LETTER EVALUATION**

**Evaluation Criteria:**
- Cover letter customization and personalization
- Understanding of organization's mission and values
- Professional writing quality and attention to detail
- Articulation of fit for this specific role
- Proactive addressing of resume gaps or career transitions

**Application Quality Scoring:**
- **90-100:** **Exceptional** - Highly customized cover letter demonstrating deep research about organization, compelling narrative about fit, excellent professional writing, addresses any resume gaps or transitions proactively
- **80-89:** **Strong** - Personalized cover letter with clear articulation of fit and genuine interest, professional writing quality, shows understanding of role and organization beyond job posting
- **75-79:** **Adequate** - Generic but acceptable cover letter with basic customization and standard professional quality, OR no cover letter when one was not required
- **60-74:** **Weak** - Template letter with minimal customization, poor writing quality, generic statements, OR missing when expected/requested by organization
- **Below 60:** **Concerning** - Unprofessional presentation, significant grammatical errors, missing when explicitly required, raises serious communication concerns

**Impact on Overall Score:**
- An exceptional cover letter (score 95) vs. adequate (score 75) can add approximately **1 point** to the overall score
- A weak cover letter (score 65) vs. adequate (score 75) can subtract approximately **0.5 points** from the overall score
- Cover letters can be a differentiator between candidates with similar qualifications

**Example:**
Two candidates with identical Q and E scores (85 each):
- Candidate A: Application Quality = 65 (weak cover letter) → R = 82.5 → Overall = 84.5
- Candidate B: Application Quality = 95 (exceptional cover letter) → R = 90 → Overall = 86.5
- **Result:** Candidate B ranks higher due to superior application quality showing better communication and genuine interest

**Scoring Algorithm**:
```
R = (Employment_Gaps × 0.25) + (Job_Hopping × 0.25) + (Skill_Currency × 0.25) + (Application_Quality × 0.25)
```

**Example Calculation**:
```
Candidate profile:
- Employment Gaps: 90 (one gap explained: graduate school)
- Job Hopping: 85 (stable progression with 2 logical moves)
- Skill Currency: 95 (currently using required skills)
- Application Quality: 88 (strong personalized cover letter)

R = (90 × 0.25) + (85 × 0.25) + (95 × 0.25) + (88 × 0.25)
R = 22.5 + 21.25 + 23.75 + 22
R = 89.5
```

---

## Stage 1: Overall Score Calculation Example

**Scenario**: Software Engineer position

**Input Scores**:
- Q (Qualifications) = 77.75
- E (Experience) = 92.5
- R (Risk Flags) = 85

**Calculation**:
```
Overall Score = (77.75 × 0.40) + (92.5 × 0.40) + (85 × 0.20)
Overall Score = 31.10 + 37.00 + 17.00
Overall Score = 85.10
```

**Decision**: **ADVANCE TO INTERVIEW** (score ≥ 85)

---

## Stage 2: Final Hiring Decision (Post-Interview Assessment)

**Purpose**: Determine job offer readiness by integrating resume, interview performance, and references.

**Formula**:
```
Final Score = (S1 × 0.25) + (I × 0.50) + (Ref × 0.25)

Where:
  S1 = Stage 1 Resume Score (0-100)
  I = Interview Score (0-100)
  Ref = Reference Check Score (0-100)
```

**Decision Thresholds**:
- **90-100**: `STRONG HIRE` – Exceptional candidate, make offer immediately
- **75-89**: `HIRE` – Solid candidate, make offer with standard terms
- **60-74**: `HOLD` – Borderline, compare with other finalists
- **0-59**: `DO NOT HIRE` – Does not meet bar for this role

---

### Interview Score (I) – Weight: 50%

**Rationale**: Interview performance is the strongest predictor of job success (r = 0.51, Schmidt & Hunter meta-analysis).

**Evaluation Methodology** (Structured Behavioral Interview):

| Competency Area | Weight | Assessment Method |
|----------------|--------|------------------|
| Technical Competence | 35% | Skills demonstration, problem-solving exercises |
| Cultural Fit | 25% | Values alignment, team dynamics assessment |
| Communication Skills | 20% | Clarity, professionalism, stakeholder management |
| Problem-Solving Ability | 15% | Analytical thinking, situational judgment |
| Motivation & Interest | 5% | Role understanding, career alignment |

**Scoring Algorithm**:
```
I = (Tech × 0.35) + (Cult × 0.25) + (Comm × 0.20) + (PS × 0.15) + (Mot × 0.05)

Each competency scored 0-100 using standardized rubrics
```

---

### Reference Check Score (Ref) – Weight: 25%

**Evaluation Methodology** (Standardized Reference Interview):

| Reference Area | Weight | Assessment Method |
|---------------|--------|------------------|
| Performance Verification | 40% | Confirmation of achievements and impact |
| Work Ethic & Reliability | 25% | Attendance, deadline adherence, accountability |
| Teamwork & Collaboration | 20% | Interpersonal effectiveness, conflict resolution |
| Managerial Feedback | 10% | Direct supervisor assessment |
| Rehire Willingness | 5% | Would former employer rehire? (Yes/No) |

**Scoring Algorithm**:
```
Ref = (Perf × 0.40) + (Work × 0.25) + (Team × 0.20) + (Mgr × 0.10) + (Rehire × 0.05)

Rehire Score: Yes = 100, Maybe = 50, No = 0
```

---

## Stage 2: Overall Score Calculation Example

**Scenario**: Software Engineer finalist

**Input Scores**:
- S1 (Stage 1 Resume) = 85.10
- I (Interview) = 92
- Ref (References) = 88

**Calculation**:
```
Final Score = (85.10 × 0.25) + (92 × 0.50) + (88 × 0.25)
Final Score = 21.28 + 46.00 + 22.00
Final Score = 89.28
```

**Decision**: **HIRE** (75-89 range) – Solid candidate, extend offer

---

## Methodological Rigor & Repeatability

### 1. **Standardization**
- All candidates for the same role use identical scoring criteria
- Weighted formulas eliminate subjective bias
- Structured evaluation format ensures consistency across evaluators

### 2. **Validity & Reliability**
- **Content Validity**: Criteria directly linked to job requirements
- **Criterion Validity**: Weights based on meta-analytic research (Schmidt & Hunter, 1998; Huffcutt & Arthur, 1994)
- **Inter-Rater Reliability**: Structured rubrics achieve r > 0.80 agreement

### 3. **Legal Defensibility** (EEOC Compliance)
- **Job-Related**: All criteria tied to bona fide occupational qualifications (BFOQ)
- **Consistent Application**: Same standards applied to all candidates
- **Documentation**: Transparent scoring with audit trail
- **Adverse Impact**: Regular analysis to detect disparate impact (4/5ths rule)

### 4. **Transparency**
- Candidates can understand why they were scored a certain way
- Hiring managers can explain decisions with data
- Audit trail maintains scoring justification

---

## Calibration & Continuous Improvement

### Threshold Validation
The scoring thresholds (85+ Interview, 70-84 Phone Screen, etc.) are calibrated using:
1. **Historical Performance Data**: Track hire success rates by score range
2. **False Positive/Negative Analysis**: Monitor candidates who exceed/miss thresholds
3. **Annual Recalibration**: Adjust thresholds based on hiring outcomes

### Weight Optimization
Sub-component weights are validated through:
- **Predictive Analytics**: Correlation between scores and post-hire performance reviews
- **Hiring Manager Feedback**: Qualitative input on candidate quality
- **Time-to-Fill Metrics**: Balance selectivity with efficiency

---

## AI Integration: Claude 3.5 Haiku

### Role of AI
- **Pattern Recognition**: Identifies skills, experience, and risk flags from unstructured resume text
- **Consistency**: Applies scoring rubrics uniformly across all candidates
- **Speed**: Evaluates resumes in seconds vs. hours for manual review
- **Objectivity**: Removes unconscious bias from initial screening

### Human Oversight
- Hiring managers review AI scores and make final decisions
- Manual overrides documented with justification
- AI used as decision support, not autonomous decision-making

---

## References & Research Foundation

1. **Schmidt, F. L., & Hunter, J. E. (1998)**. "The validity and utility of selection methods in personnel psychology: Practical and theoretical implications of 85 years of research findings." *Psychological Bulletin*, 124(2), 262-274.

2. **Huffcutt, A. I., & Arthur, W. (1994)**. "Hunter and Hunter (1984) revisited: Interview validity for entry-level jobs." *Journal of Applied Psychology*, 79(2), 184-190.

3. **Equal Employment Opportunity Commission (EEOC)**. *Uniform Guidelines on Employee Selection Procedures* (1978). 29 C.F.R. § 1607.

4. **Society for Industrial and Organizational Psychology (SIOP)**. *Principles for the Validation and Use of Personnel Selection Procedures* (2018).

---

## Summary Table: Complete Scoring Breakdown

| Stage | Component | Weight | Sub-Components |
|-------|-----------|--------|----------------|
| **Stage 1** | Qualifications (Q) | 40% | Must-haves (60%), Preferreds (25%), Education (10%), Certs (5%) |
| | Experience (E) | 40% | Years (40%), Progression (30%), Industry (20%), Complexity (10%) |
| | Risk Flags (R) | 20% | Deductive scoring from 100 baseline |
| **Stage 2** | Stage 1 Score | 25% | Carried forward from resume screening |
| | Interview (I) | 50% | Technical (35%), Culture (25%), Communication (20%), Problem-Solving (15%), Motivation (5%) |
| | References (Ref) | 25% | Performance (40%), Work Ethic (25%), Teamwork (20%), Manager (10%), Rehire (5%) |

---

## Version History

- **v1.0** (2025-11-03): Initial methodology documentation
- Based on Resume Scanner Pro codebase and recruiting-evaluation framework
- Aligned with evidence-based hiring research and EEOC guidelines

---

*This methodology is proprietary to Resume Scanner Pro and reflects current best practices in talent acquisition and assessment science.*
